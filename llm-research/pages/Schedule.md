- Presentation Due Date: Monday, Jul 24th
- [[Research]]
- Outline
	- **Week 1 (May 8 - May 12)**: 
	  Research existing language models and their hardware requirements + address dataset for langchain
	- **Week 2 (May 15 - May 19)** 
	  Investigate the latency of models on neural engine as LLM increases in size to find optimal model size
		- chatGPT latency is 55ms
		- [Constraints](https://github.com/kendreaditya/neural-engine-benchmark)
	- **Week 3 (May 22 - May 26)**
		- [Constraints](https://github.com/kendreaditya/neural-engine-benchmark)
	- **Week 4 (May 29 - June 2)**
		- [[State of GPT]]
	- **Week 5 (June 5 - June 9)**
	- **Week 6 (June 12 - June 16)**
	  Search for pretrained model
		- Rapid API [email](https://mail.google.com/mail/u/0/#inbox/FMfcgzGsmhfcTwGFSPQzjxSGrCLfhRxF)
		- [[Orca]]
		- GPT Series
		- [[The Plan]]
		- [DINO (Datasets From Instructions)](http://timoschick.com/research/2021/05/19/dino.html)
	- **Week 7 (June 19 - June 23)**
	  Set-up training system + dry runs
	- **Week 8 (June 26 - June 30)**
	  Start fine-tuning
	- **Week 9 (July 3 - July 7)**
	  Continue fine-tuning
	- **Week 10 (July 10 - July 14)**
	  Get the model running on neural engine and evaluate locally-run language model
	  Compare and contrast models
	- **Week 11 (July 17 - July 21)**
	  Work on presentation and paper
		- Presentation like [[State of GPT]] (format + theme)
-